"""
ê±´ê°•ë³´í—˜ì‹¬ì‚¬í‰ê°€ì›(HIRA) í•­ì•”í™”í•™ìš”ë²• MCP Server.

Claude Desktop / LLMì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ MCP Toolì„ ì œê³µí•©ë‹ˆë‹¤.

Tools:
  1. hira_check_updates   â€” ì„œë²„ì˜ ìµœì‹  íŒŒì¼ê³¼ ë¡œì»¬ íŒŒì¼ ë¹„êµ (SHA-256)
  2. hira_download_files   â€” ìµœì‹  íŒŒì¼ ë‹¤ìš´ë¡œë“œ
  3. hira_get_status        â€” í˜„ì¬ ëª¨ë‹ˆí„°ë§ ìƒíƒœ ì¡°íšŒ
  4. hira_list_files        â€” HIRA í˜ì´ì§€ì˜ íŒŒì¼ ëª©ë¡ ìŠ¤ìº”
  5. hira_list_history      â€” íŒŒì¼ ë³€ê²½ ì´ë ¥ ì¡°íšŒ
  6. hira_cleanup           â€” êµ¬ ë²„ì „ íŒŒì¼ ì •ë¦¬
  7. hira_scheduler_control â€” ìŠ¤ì¼€ì¤„ëŸ¬ on/off/ìƒíƒœ/ì¦‰ì‹œì‹¤í–‰
  8. hira_read_excel        â€” Excel íŒŒì¼ ì½ê¸° (ë¨¸ì§€ì…€ ì²˜ë¦¬, ì•”ì¢… í•„í„°)
  9. hira_read_pdf          â€” PDF í•˜ì´ë¸Œë¦¬ë“œ ì½ê¸° (í…ìŠ¤íŠ¸+ì´ë¯¸ì§€, ì„¹ì…˜ íƒìƒ‰)

Transport: stdio (Claude Desktop í‘œì¤€)
"""

from __future__ import annotations

import asyncio
import json
import logging
import os
import sys
from pathlib import Path
from typing import Any

from dotenv import load_dotenv
from mcp.server import Server
from mcp.server.stdio import stdio_server
from mcp.types import ImageContent, TextContent, Tool

from .scraper import (
    FILE_IDENTIFIERS,
    MetadataStore,
    check_for_updates,
    cleanup_old_files,
    download_file,
    ensure_playwright,
    scrape_file_list,
)
from .scheduler import HiraScheduler
from .reader import read_excel, read_pdf

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()

DATA_DIR = Path(
    os.getenv("HIRA_DATA_DIR", "~/.hira-anticancer-data")
).expanduser()

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(name)s] %(levelname)s: %(message)s",
    handlers=[logging.StreamHandler(sys.stderr)],
)
logger = logging.getLogger("hira-mcp-server")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MCP Server ì¸ìŠ¤í„´ìŠ¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
server = Server("hira-anticancer-mcp-server")
_scheduler: HiraScheduler | None = None


def _get_scheduler() -> HiraScheduler:
    """ì‹±ê¸€í†¤ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _scheduler
    if _scheduler is None:
        _scheduler = HiraScheduler(DATA_DIR)
    return _scheduler


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Tool ëª©ë¡ ë“±ë¡
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOOLS = [
    Tool(
        name="hira_check_updates",
        description=(
            "HIRA ì‹¬ì‚¬í‰ê°€ì›ì˜ í•­ì•”í™”í•™ìš”ë²• ê³µê³  íŒŒì¼(í—ˆê°€ì´ˆê³¼ í•­ì•”ìš”ë²•, "
            "í•­ì•”í™”í•™ìš”ë²• ê³µê³ ì „ë¬¸)ì„ ì„œë²„ì—ì„œ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¡œì»¬ íŒŒì¼ê³¼ "
            "SHA-256 í•´ì‹œ/í¬ê¸°ë¥¼ ë¹„êµí•©ë‹ˆë‹¤. ë³€ê²½ ê°ì§€ ì‹œ ìë™ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."
        ),
        inputSchema={
            "type": "object",
            "properties": {},
        },
    ),
    Tool(
        name="hira_download_files",
        description=(
            "HIRA í˜ì´ì§€ì—ì„œ ì§€ì •ëœ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. "
            "file_keyë¥¼ ìƒëµí•˜ë©´ ëª¨ë“  ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."
        ),
        inputSchema={
            "type": "object",
            "properties": {
                "file_key": {
                    "type": "string",
                    "description": (
                        "ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ í‚¤. ê°€ëŠ¥í•œ ê°’: "
                        "í—ˆê°€ì´ˆê³¼_í•­ì•”ìš”ë²•, í•­ì•”í™”í•™ìš”ë²•_ê³µê³ ì „ë¬¸. "
                        "ìƒëµ ì‹œ ì „ì²´ ë‹¤ìš´ë¡œë“œ"
                    ),
                },
            },
        },
    ),
    Tool(
        name="hira_get_status",
        description=(
            "í˜„ì¬ ëª¨ë‹ˆí„°ë§ ìƒíƒœë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤: ê° íŒŒì¼ì˜ ìµœì‹  ë²„ì „, "
            "í•´ì‹œê°’, í¬ê¸°, ë§ˆì§€ë§‰ í™•ì¸ ì‹œê°, ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ë“±"
        ),
        inputSchema={"type": "object", "properties": {}},
    ),
    Tool(
        name="hira_list_files",
        description=(
            "HIRA í•­ì•”í™”í•™ìš”ë²• í˜ì´ì§€ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤ìº”í•˜ì—¬ "
            "ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ íŒŒì¼ ëª©ë¡ê³¼ ë§í¬ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."
        ),
        inputSchema={"type": "object", "properties": {}},
    ),
    Tool(
        name="hira_list_history",
        description="íŠ¹ì • íŒŒì¼ì˜ ë³€ê²½ ì´ë ¥(ë‹¤ìš´ë¡œë“œ íˆìŠ¤í† ë¦¬)ì„ ì¡°íšŒí•©ë‹ˆë‹¤.",
        inputSchema={
            "type": "object",
            "properties": {
                "file_key": {
                    "type": "string",
                    "description": (
                        "ì¡°íšŒí•  íŒŒì¼ í‚¤: í—ˆê°€ì´ˆê³¼_í•­ì•”ìš”ë²• ë˜ëŠ” í•­ì•”í™”í•™ìš”ë²•_ê³µê³ ì „ë¬¸"
                    ),
                },
                "limit": {
                    "type": "integer",
                    "description": "ìµœëŒ€ ë°˜í™˜ ê°œìˆ˜ (ê¸°ë³¸ 10)",
                    "default": 10,
                },
            },
            "required": ["file_key"],
        },
    ),
    Tool(
        name="hira_cleanup",
        description=(
            "ë°ì´í„° ë””ë ‰í† ë¦¬ì—ì„œ êµ¬ ë²„ì „ íŒŒì¼ì„ ì •ë¦¬í•©ë‹ˆë‹¤. "
            "ìµœì‹ (current) íŒŒì¼ê³¼ *_latest íŒŒì¼ë§Œ ë³´ì¡´í•©ë‹ˆë‹¤."
        ),
        inputSchema={"type": "object", "properties": {}},
    ),
    Tool(
        name="hira_scheduler_control",
        description=(
            "ë§¤ì¼ ìë™ ì—…ë°ì´íŠ¸ í™•ì¸ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì œì–´í•©ë‹ˆë‹¤. "
            "í™œì„±í™”/ë¹„í™œì„±í™”, ì‹œê° ë³€ê²½, ì¦‰ì‹œ ì‹¤í–‰, ìƒíƒœ ì¡°íšŒê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        ),
        inputSchema={
            "type": "object",
            "properties": {
                "action": {
                    "type": "string",
                    "enum": ["status", "enable", "disable", "run_now", "set_time"],
                    "description": (
                        "status: ìƒíƒœ ì¡°íšŒ, enable: í™œì„±í™”(ON), "
                        "disable: ë¹„í™œì„±í™”(OFF), "
                        "run_now: ì¦‰ì‹œ 1íšŒ ì‹¤í–‰, "
                        "set_time: ì²´í¬ ì‹œê° ë³€ê²½"
                    ),
                },
                "hour": {
                    "type": "integer",
                    "description": "set_time ì‹œ ì‚¬ìš©í•  ì‹œ(0-23, KST)",
                },
                "minute": {
                    "type": "integer",
                    "description": "set_time ì‹œ ì‚¬ìš©í•  ë¶„(0-59)",
                    "default": 0,
                },
            },
            "required": ["action"],
        },
    ),
    # â”€â”€ íŒŒì¼ ë¦¬ë” Tool â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Tool(
        name="hira_read_excel",
        description=(
            "ë‹¤ìš´ë¡œë“œëœ HIRA í—ˆê°€ì´ˆê³¼ í•­ì•”ìš”ë²• Excel íŒŒì¼ì„ ì½ìŠµë‹ˆë‹¤. "
            "ê¸°ë³¸ì ìœ¼ë¡œ 'ì¸ì •ë˜ê³  ìˆëŠ” í—ˆê°€ì´ˆê³¼ í•­ì•”ìš”ë²•(ìš©ë²•ìš©ëŸ‰í¬í•¨)' ì‹œíŠ¸ë¥¼ ì½ìœ¼ë©°, "
            "ì•”ì¢…ë³„ í•„í„°ë§ì„ ì§€ì›í•©ë‹ˆë‹¤. ê²°ê³¼ëŠ” Markdown í…Œì´ë¸”ë¡œ ë°˜í™˜ë©ë‹ˆë‹¤.\n\n"
            "âš ï¸ ì¤‘ìš”: ê¸°ë³¸ ì‹œíŠ¸('ì¸ì •ë˜ê³  ìˆëŠ” í—ˆê°€ì´ˆê³¼ í•­ì•”ìš”ë²•')ì—ì„œ ë¨¼ì € ê²€ìƒ‰í•˜ì„¸ìš”. "
            "ë‹¤ë¥¸ ì‹œíŠ¸ë¥¼ ì¡°íšŒí•˜ê¸° ì „ì— ë°˜ë“œì‹œ ì‚¬ìš©ìì—ê²Œ ì–´ë–¤ ì‹œíŠ¸ë¥¼ ì›í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n\n"
            "ì‹œíŠ¸ ëª©ë¡:\n"
            "- ì¸ì •ë˜ê³  ìˆëŠ” í—ˆê°€ì´ˆê³¼ í•­ì•”ìš”ë²•(ìš©ë²•ìš©ëŸ‰í¬í•¨): ìŠ¹ì¸ëœ í—ˆê°€ì´ˆê³¼ ìš”ë²• (ê¸°ë³¸)\n"
            "- ê²€í† ì¤‘ì¸ í—ˆê°€ì´ˆê³¼ í•­ì•”ìš”ë²•: âš ï¸ ì•„ì§ ìŠ¹ì¸ë˜ì§€ ì•ŠìŒ, ê²€í†  ì¤‘\n"
            "- ë¶ˆìŠ¹ì¸ ìš”ë²•: âš ï¸ ìŠ¹ì¸ ê±°ë¶€ë¨, ê¸‰ì—¬ ë¶ˆì¸ì •\n"
            "- ì•ˆë‚´: íŒŒì¼ ì•ˆë‚´ ì •ë³´\n"
            "- í—ˆê°€ì´ˆê³¼ í•­ì•”ìš”ë²• ë³€ê²½ëŒ€ë¹„í‘œ: ë³€ê²½ ì´ë ¥"
        ),
        inputSchema={
            "type": "object",
            "properties": {
                "file_key": {
                    "type": "string",
                    "description": (
                        "ì½ì„ íŒŒì¼ í‚¤. ê¸°ë³¸: 'í—ˆê°€ì´ˆê³¼_í•­ì•”ìš”ë²•'. "
                        "ê°€ëŠ¥í•œ ê°’: í—ˆê°€ì´ˆê³¼_í•­ì•”ìš”ë²•, í•­ì•”í™”í•™ìš”ë²•_ê³µê³ ì „ë¬¸"
                    ),
                    "default": "í—ˆê°€ì´ˆê³¼_í•­ì•”ìš”ë²•",
                },
                "sheet": {
                    "type": "string",
                    "description": (
                        "ì‹œíŠ¸ ì´ë¦„. ìƒëµ ì‹œ 'ì¸ì •ë˜ê³  ìˆëŠ” í—ˆê°€ì´ˆê³¼ í•­ì•”ìš”ë²•(ìš©ë²•ìš©ëŸ‰í¬í•¨)' "
                        "ì‹œíŠ¸ë¥¼ ìë™ ì„ íƒí•©ë‹ˆë‹¤. "
                        "ë‹¤ë¥¸ ì‹œíŠ¸ ì¡°íšŒ ì „ ì‚¬ìš©ì í™•ì¸ í•„ìˆ˜!"
                    ),
                },
                "cancer_type": {
                    "type": "string",
                    "description": (
                        "ì•”ì¢… í•„í„° í‚¤ì›Œë“œ (ì˜ˆ: 'ë‚œì†Œì•”', 'ìê¶ê²½ë¶€ì•”', "
                        "'ìœ ë°©ì•”', 'íì•”'). ìƒëµ ì‹œ ì „ì²´ ë°ì´í„°"
                    ),
                },
                "max_rows": {
                    "type": "integer",
                    "description": "ìµœëŒ€ ë°˜í™˜ í–‰ ìˆ˜ (ê¸°ë³¸ 200, í† í° ì œí•œ ë°©ì§€)",
                    "default": 200,
                },
            },
        },
    ),
    Tool(
        name="hira_read_pdf",
        description=(
            "ë‹¤ìš´ë¡œë“œëœ HIRA í•­ì•”í™”í•™ìš”ë²• ê³µê³ ì „ë¬¸ PDF(274p)ë¥¼ ì½ìŠµë‹ˆë‹¤. "
            "ì¶”ì²œ ì‚¬ìš©ë²•: (1) cancer_typeìœ¼ë¡œ ì•”ì¢…ë³„ í˜ì´ì§€ ìë™ ì¡°íšŒ, "
            "(2) searchë¡œ ì•½ì œëª…/í‚¤ì›Œë“œ ê²€ìƒ‰, (3) pagesë¡œ íŠ¹ì • í˜ì´ì§€ ì§ì ‘ ì—´ëŒ. "
            "íŒŒë¼ë¯¸í„° ì—†ì´ í˜¸ì¶œí•˜ë©´ ëª©ì°¨(ì•”ì¢…ë³„ í˜ì´ì§€ ë§¤í•‘)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. "
            "í…Œì´ë¸” í˜ì´ì§€ëŠ” ì´ë¯¸ì§€ë¡œ, í…ìŠ¤íŠ¸ í˜ì´ì§€ëŠ” í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤. "
            "ë„“ì€ ë²”ìœ„ ì¡°íšŒ ì‹œ text_only=trueë¡œ 1MB ì œí•œì„ íšŒí”¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        ),
        inputSchema={
            "type": "object",
            "properties": {
                "file_key": {
                    "type": "string",
                    "description": (
                        "ì½ì„ íŒŒì¼ í‚¤. ê¸°ë³¸: 'í•­ì•”í™”í•™ìš”ë²•_ê³µê³ ì „ë¬¸'. "
                        "ê°€ëŠ¥í•œ ê°’: í—ˆê°€ì´ˆê³¼_í•­ì•”ìš”ë²•, í•­ì•”í™”í•™ìš”ë²•_ê³µê³ ì „ë¬¸"
                    ),
                    "default": "í•­ì•”í™”í•™ìš”ë²•_ê³µê³ ì „ë¬¸",
                },
                "cancer_type": {
                    "type": "string",
                    "description": (
                        "ì•”ì¢…ëª…ìœ¼ë¡œ í•´ë‹¹ í˜ì´ì§€ ë²”ìœ„ë¥¼ ìë™ ì¡°íšŒí•©ë‹ˆë‹¤. "
                        "í•œê¸€/ì˜ë¬¸ ëª¨ë‘ ì§€ì›. "
                        "ì˜ˆ: 'ë‚œì†Œì•”', 'ovarian', 'ìœ ë°©ì•”', 'breast', "
                        "'ë¹„ì†Œì„¸í¬íì•”', 'NSCLC'"
                    ),
                },
                "search": {
                    "type": "string",
                    "description": (
                        "PDF ì „ì²´ì—ì„œ í‚¤ì›Œë“œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. "
                        "ì•½ì œëª…, ì•”ì¢…ëª…, ìš”ë²•ëª… ë“±ìœ¼ë¡œ ê²€ìƒ‰ ê°€ëŠ¥. "
                        "ì˜ˆ: 'trastuzumab deruxtecan', 'pembrolizumab', 'ë‚œì†Œì•”'"
                    ),
                },
                "pages": {
                    "type": "string",
                    "description": (
                        "í˜ì´ì§€ ë²”ìœ„ (ì˜ˆ: '1-10', '5', '1,3,7-10'). 1-indexed. "
                        "í…Œì´ë¸”ì´ ë§ì€ ë²”ìœ„ëŠ” 2~3pì”© ìš”ì²­ ê¶Œì¥."
                    ),
                },
                "section": {
                    "type": "string",
                    "description": (
                        "ì„¹ì…˜ í•„í„°. ê°€ëŠ¥í•œ ê°’: "
                        "ì¼ë°˜ì›ì¹™, ì•”ì¢…ë³„í•­ì•”ìš”ë²•, í•­ì•”ë©´ì—­ìš”ë²•ì œ, í•­êµ¬í† ì œ, ë³„í‘œ, ë¶€ë¡"
                    ),
                },
                "text_only": {
                    "type": "boolean",
                    "description": (
                        "trueë¡œ ì„¤ì •í•˜ë©´ ì´ë¯¸ì§€ ì—†ì´ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤. "
                        "ë„“ì€ í˜ì´ì§€ ë²”ìœ„ ì¡°íšŒ ì‹œ 1MB ì œí•œ íšŒí”¼ì— ìœ ìš©í•©ë‹ˆë‹¤."
                    ),
                    "default": False,
                },
            },
        },
    ),
]


@server.list_tools()
async def list_tools() -> list[Tool]:
    return TOOLS


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Tool ì‹¤í–‰ í•¸ë“¤ëŸ¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _to_text(data: Any) -> list[TextContent]:
    """ê²°ê³¼ë¥¼ MCP TextContentë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if isinstance(data, str):
        return [TextContent(type="text", text=data)]
    return [TextContent(type="text", text=json.dumps(data, ensure_ascii=False, indent=2))]


@server.call_tool()
async def call_tool(name: str, arguments: dict) -> list[TextContent | ImageContent]:
    """ë“±ë¡ëœ MCP Toolì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    logger.info(f"Tool í˜¸ì¶œ: {name}({arguments})")

    try:
        if name == "hira_check_updates":
            return await _handle_check_updates(arguments)
        elif name == "hira_download_files":
            return await _handle_download_files(arguments)
        elif name == "hira_get_status":
            return await _handle_get_status(arguments)
        elif name == "hira_list_files":
            return await _handle_list_files(arguments)
        elif name == "hira_list_history":
            return await _handle_list_history(arguments)
        elif name == "hira_cleanup":
            return await _handle_cleanup(arguments)
        elif name == "hira_scheduler_control":
            return await _handle_scheduler(arguments)
        elif name == "hira_read_excel":
            return await _handle_read_excel(arguments)
        elif name == "hira_read_pdf":
            return await _handle_read_pdf(arguments)
        else:
            return _to_text(f"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {name}")
    except Exception as exc:
        logger.error(f"Tool ì‹¤í–‰ ì˜¤ë¥˜ [{name}]: {exc}", exc_info=True)
        return _to_text(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {exc}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê°œë³„ Tool í•¸ë“¤ëŸ¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def _handle_check_updates(args: dict) -> list[TextContent]:
    """hira_check_updates ì‹¤í–‰"""
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    results = await check_for_updates(DATA_DIR)

    # ì‚¬ëŒì´ ì½ê¸° ì¢‹ì€ ìš”ì•½ ìƒì„±
    summary_lines = [
        "ğŸ“‹ HIRA í•­ì•”í™”í•™ìš”ë²• íŒŒì¼ ì—…ë°ì´íŠ¸ í™•ì¸ ê²°ê³¼",
        f"í™•ì¸ ì‹œê°: {results['checked_at']}",
        "â”€" * 40,
    ]
    for key, info in results["files"].items():
        has = info.get("has_update")
        if has is True:
            summary_lines.append(f"ğŸ”´ {key}: ë³€ê²½ ê°ì§€!")
            summary_lines.append(f"   â†’ {info.get('reason')}")
            if info.get("new_size"):
                summary_lines.append(f"   í¬ê¸°: {info['new_size']:,} bytes")
        elif has is False:
            summary_lines.append(f"ğŸŸ¢ {key}: ë³€ê²½ ì—†ìŒ")
        else:
            summary_lines.append(f"âš ï¸ {key}: í™•ì¸ ì‹¤íŒ¨ â€” {info.get('reason')}")
    summary_lines.append("â”€" * 40)

    return _to_text("\n".join(summary_lines))


async def _handle_download_files(args: dict) -> list[TextContent]:
    """hira_download_files ì‹¤í–‰"""
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    store = MetadataStore(DATA_DIR)

    file_key = args.get("file_key")
    keys = [file_key] if file_key else list(FILE_IDENTIFIERS.keys())

    results = []
    for key in keys:
        if key not in FILE_IDENTIFIERS:
            results.append(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼ í‚¤: {key}")
            continue

        record = await download_file(key, DATA_DIR)
        store.update(key, record)
        results.append(
            f"âœ… {key} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\n"
            f"   íŒŒì¼: {record['filename']}\n"
            f"   í¬ê¸°: {record['size']:,} bytes\n"
            f"   SHA-256: {record['sha256'][:16]}â€¦"
        )

    # êµ¬íŒŒì¼ ì •ë¦¬
    cleanup_old_files(DATA_DIR, keep_latest_only=True)

    return _to_text("\n\n".join(results))


async def _handle_get_status(args: dict) -> list[TextContent]:
    """hira_get_status ì‹¤í–‰"""
    store = MetadataStore(DATA_DIR)
    status = store.get_all_status()
    scheduler = _get_scheduler()
    sched_status = scheduler.get_status()

    lines = [
        "ğŸ“Š HIRA í•­ì•”í™”í•™ìš”ë²• ëª¨ë‹ˆí„°ë§ í˜„í™©",
        f"ë°ì´í„° ë””ë ‰í† ë¦¬: {DATA_DIR}",
        "â”€" * 40,
    ]

    for key, info in status.items():
        cur = info["current"]
        lines.append(f"ğŸ“ {key}")
        if cur:
            lines.append(f"   ìµœì‹  íŒŒì¼: {cur['filename']}")
            lines.append(f"   í¬ê¸°: {cur['size']:,} bytes")
            lines.append(f"   SHA-256: {cur['sha256'][:16]}â€¦")
            lines.append(f"   ë‹¤ìš´ë¡œë“œ: {cur['downloaded_at']}")
            lines.append(f"   ì¶œì²˜ í…ìŠ¤íŠ¸: {cur.get('source_text', '?')}")
        else:
            lines.append("   (ì•„ì§ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ì—†ìŒ)")
        lines.append(f"   ì´ ë²„ì „ ìˆ˜: {info['total_versions']}")
        lines.append("")

    lines.append("â”€" * 40)
    lines.append("â° ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ")
    lines.append(f"   í™œì„±: {'ON âœ…' if sched_status['enabled'] else 'OFF âŒ'}")
    lines.append(f"   ì£¼ê¸°: {sched_status['schedule']}")
    lines.append(f"   ë‹¤ìŒ ì‹¤í–‰: {sched_status['next_run_in']}")
    lines.append(f"   ë§ˆì§€ë§‰ ì‹¤í–‰: {sched_status.get('last_run', 'ì—†ìŒ')}")

    return _to_text("\n".join(lines))


async def _handle_list_files(args: dict) -> list[TextContent]:
    """hira_list_files ì‹¤í–‰"""
    files = await scrape_file_list()

    if not files:
        return _to_text("HIRA í˜ì´ì§€ì—ì„œ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    lines = [
        "ğŸ“„ HIRA í•­ì•”í™”í•™ìš”ë²• í˜ì´ì§€ íŒŒì¼ ëª©ë¡",
        "â”€" * 40,
    ]
    for f in files:
        lines.append(f"  â€¢ [{f['file_key']}] {f['link_text']}")

    return _to_text("\n".join(lines))


async def _handle_list_history(args: dict) -> list[TextContent]:
    """hira_list_history ì‹¤í–‰"""
    file_key = args["file_key"]
    limit = args.get("limit", 10)

    if file_key not in FILE_IDENTIFIERS:
        return _to_text(
            f"ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼ í‚¤: {file_key}\n"
            f"ê°€ëŠ¥í•œ ê°’: {', '.join(FILE_IDENTIFIERS.keys())}"
        )

    store = MetadataStore(DATA_DIR)
    current = store.get_current(file_key)
    history = store.get_history(file_key)[:limit]

    lines = [f"ğŸ“œ {file_key} ë³€ê²½ ì´ë ¥", "â”€" * 40]

    if current:
        lines.append(f"[í˜„ì¬] {current['filename']}")
        lines.append(f"       ë‹¤ìš´ë¡œë“œ: {current['downloaded_at']}")
        lines.append(f"       í¬ê¸°: {current['size']:,} bytes")
        lines.append(f"       SHA-256: {current['sha256'][:16]}â€¦")
    else:
        lines.append("(í˜„ì¬ íŒŒì¼ ì—†ìŒ)")

    if history:
        lines.append("")
        lines.append(f"ì´ì „ ë²„ì „ ({len(history)}ê°œ):")
        for i, h in enumerate(history, 1):
            lines.append(f"  {i}. {h['filename']} ({h['downloaded_at']})")
    else:
        lines.append("\n(ì´ì „ ë²„ì „ ì—†ìŒ)")

    return _to_text("\n".join(lines))


async def _handle_cleanup(args: dict) -> list[TextContent]:
    """hira_cleanup ì‹¤í–‰"""
    result = cleanup_old_files(DATA_DIR, keep_latest_only=True)

    lines = ["ğŸ§¹ êµ¬ íŒŒì¼ ì •ë¦¬ ê²°ê³¼", "â”€" * 40]
    if result["deleted"]:
        lines.append(f"ì‚­ì œ: {len(result['deleted'])}ê°œ")
        for d in result["deleted"]:
            lines.append(f"  âœ— {d}")
    else:
        lines.append("ì‚­ì œí•  êµ¬ íŒŒì¼ ì—†ìŒ")

    lines.append(f"\në³´ì¡´: {len(result['kept'])}ê°œ")
    for k in result["kept"]:
        lines.append(f"  âœ“ {k}")

    if result["errors"]:
        lines.append(f"\nì˜¤ë¥˜: {len(result['errors'])}ê°œ")
        for e in result["errors"]:
            lines.append(f"  âš ï¸ {e}")

    return _to_text("\n".join(lines))


async def _handle_scheduler(args: dict) -> list[TextContent]:
    """hira_scheduler_control ì‹¤í–‰"""
    action = args["action"]
    scheduler = _get_scheduler()

    if action == "status":
        status = scheduler.get_status()
        lines = [
            "â° ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ",
            f"  í™œì„±: {'ON âœ…' if status['enabled'] else 'OFF âŒ'}",
            f"  ì‹¤í–‰ ì¤‘: {'ì˜ˆ' if status['running'] else 'ì•„ë‹ˆì˜¤'}",
            f"  ì£¼ê¸°: {status['schedule']}",
            f"  ë‹¤ìŒ ì‹¤í–‰: {status['next_run_in']}",
            f"  ë§ˆì§€ë§‰ ì‹¤í–‰: {status.get('last_run', 'ì—†ìŒ')}",
            f"  ë§ˆì§€ë§‰ ê²°ê³¼: {status.get('last_result_summary', 'ì—†ìŒ')}",
        ]
        return _to_text("\n".join(lines))

    elif action == "enable":
        status = scheduler.enable()
        # ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì•„ì§ ì‹œì‘ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì‹œì‘
        if not scheduler._running:
            await scheduler.start()
        return _to_text("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ í™œì„±í™”ë¨ (ON)\n"
                        f"ì£¼ê¸°: {status['schedule']}")

    elif action == "disable":
        status = scheduler.disable()
        return _to_text("âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„í™œì„±í™”ë¨ (OFF)\n"
                        "â€» ìŠ¤ì¼€ì¤„ ë£¨í”„ëŠ” ìœ ì§€ë˜ë‚˜ ì‹¤í–‰ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

    elif action == "run_now":
        result = await scheduler.run_now()
        if "error" in result:
            return _to_text(f"âš ï¸ ì¦‰ì‹œ ì‹¤í–‰ ì˜¤ë¥˜: {result['error']}")

        lines = ["ğŸ”„ ì¦‰ì‹œ ì‹¤í–‰ ì™„ë£Œ"]
        for key, info in result.get("files", {}).items():
            has = info.get("has_update")
            if has is True:
                lines.append(f"  ğŸ”´ {key}: ë³€ê²½ ê°ì§€")
            elif has is False:
                lines.append(f"  ğŸŸ¢ {key}: ë³€ê²½ ì—†ìŒ")
            else:
                lines.append(f"  âš ï¸ {key}: í™•ì¸ ì‹¤íŒ¨")
        return _to_text("\n".join(lines))

    elif action == "set_time":
        hour = args.get("hour")
        minute = args.get("minute", 0)
        if hour is None:
            return _to_text("âš ï¸ hour íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤ (0-23)")
        status = scheduler.set_schedule(hour, minute)
        return _to_text(
            f"âœ… ì²´í¬ ì‹œê° ë³€ê²½: {hour:02d}:{minute:02d} KST\n"
            f"ë‹¤ìŒ ì‹¤í–‰: {status['next_run_in']}"
        )

    else:
        return _to_text(
            f"ì•Œ ìˆ˜ ì—†ëŠ” action: {action}\n"
            "ê°€ëŠ¥í•œ ê°’: status, enable, disable, run_now, set_time"
        )


# â”€â”€ íŒŒì¼ ë¦¬ë” í•¸ë“¤ëŸ¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _resolve_latest_file(file_key: str) -> Path | None:
    """file_keyì— ëŒ€ì‘í•˜ëŠ” ìµœì‹  íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    if file_key not in FILE_IDENTIFIERS:
        return None

    # MetadataStoreì—ì„œ latest_path í™•ì¸
    store = MetadataStore(DATA_DIR)
    current = store.get_current(file_key)
    if current:
        # latest_path ìš°ì„ 
        latest_path = current.get("latest_path")
        if latest_path and Path(latest_path).exists():
            return Path(latest_path)
        # filepath fallback
        filepath = current.get("filepath")
        if filepath and Path(filepath).exists():
            return Path(filepath)

    # glob fallback: DATA_DIRì—ì„œ *_latest.* íŒ¨í„´
    for ext in [".xlsx", ".xls", ".pdf", ".hwp"]:
        candidate = DATA_DIR / f"{file_key}_latest{ext}"
        if candidate.exists():
            return candidate

    return None


async def _handle_read_excel(args: dict) -> list[TextContent | ImageContent]:
    """hira_read_excel ì‹¤í–‰"""
    file_key = args.get("file_key", "í—ˆê°€ì´ˆê³¼_í•­ì•”ìš”ë²•")

    filepath = _resolve_latest_file(file_key)
    if filepath is None:
        return _to_text(
            f"âš ï¸ '{file_key}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            f"ë¨¼ì € hira_download_filesë¡œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•´ì£¼ì„¸ìš”.\n"
            f"ë°ì´í„° ë””ë ‰í† ë¦¬: {DATA_DIR}"
        )

    # í™•ì¥ì í™•ì¸
    if filepath.suffix.lower() not in (".xlsx", ".xls"):
        return _to_text(
            f"âš ï¸ '{file_key}'ì˜ ìµœì‹  íŒŒì¼ì´ Excel í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤: "
            f"{filepath.name}\n"
            "hira_read_pdfë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”."
        )

    logger.info(f"Excel ì½ê¸°: {filepath}")
    return read_excel(
        filepath,
        sheet=args.get("sheet"),
        cancer_type=args.get("cancer_type"),
        max_rows=args.get("max_rows", 200),
    )


async def _handle_read_pdf(args: dict) -> list[TextContent | ImageContent]:
    """hira_read_pdf ì‹¤í–‰"""
    file_key = args.get("file_key", "í•­ì•”í™”í•™ìš”ë²•_ê³µê³ ì „ë¬¸")

    filepath = _resolve_latest_file(file_key)
    if filepath is None:
        return _to_text(
            f"âš ï¸ '{file_key}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            f"ë¨¼ì € hira_download_filesë¡œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•´ì£¼ì„¸ìš”.\n"
            f"ë°ì´í„° ë””ë ‰í† ë¦¬: {DATA_DIR}"
        )

    # í™•ì¥ì í™•ì¸
    if filepath.suffix.lower() != ".pdf":
        return _to_text(
            f"âš ï¸ '{file_key}'ì˜ ìµœì‹  íŒŒì¼ì´ PDF í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤: "
            f"{filepath.name}\n"
            "hira_read_excelì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”."
        )

    logger.info(f"PDF ì½ê¸°: {filepath}")
    return read_pdf(
        filepath,
        pages=args.get("pages"),
        section=args.get("section"),
        cancer_type=args.get("cancer_type"),
        search=args.get("search"),
        text_only=args.get("text_only", False),
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„œë²„ ì§„ì…ì 
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main() -> None:
    """MCP Serverë¥¼ stdio transportë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    logger.info("HIRA Anticancer MCP Server ì‹œì‘â€¦")
    logger.info(f"ë°ì´í„° ë””ë ‰í† ë¦¬: {DATA_DIR}")

    async def _run():
        # Playwright ì‚¬ì „ í™•ì¸
        await ensure_playwright()

        # ìŠ¤ì¼€ì¤„ëŸ¬ ìë™ ì‹œì‘
        scheduler = _get_scheduler()
        if scheduler._enabled:
            await scheduler.start()
            logger.info("ìŠ¤ì¼€ì¤„ëŸ¬ ìë™ ì‹œì‘ ì™„ë£Œ")

        # MCP stdio ì„œë²„ ì‹¤í–‰
        async with stdio_server() as (read_stream, write_stream):
            await server.run(
                read_stream,
                write_stream,
                server.create_initialization_options(),
            )

    asyncio.run(_run())


if __name__ == "__main__":
    main()
