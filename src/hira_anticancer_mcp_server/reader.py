"""
HIRA í•­ì•”í™”í•™ìš”ë²• íŒŒì¼ ë¦¬ë”.

Excel(í—ˆê°€ì´ˆê³¼_í•­ì•”ìš”ë²•)ê³¼ PDF(í•­ì•”í™”í•™ìš”ë²•_ê³µê³ ì „ë¬¸)ë¥¼ íŒŒì‹±í•˜ì—¬
MCP TextContent / ImageContent í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

ì „ëµ:
  - Excel: openpyxl text extraction (ë¨¸ì§€ì…€ forward-fill, data_only=True)
  - PDF:   í•˜ì´ë¸Œë¦¬ë“œ (í…ìŠ¤íŠ¸ ì „ìš© â†’ pdfplumber, í…Œì´ë¸” í¬í•¨ â†’ PyMuPDF ImageContent)
"""

from __future__ import annotations

import base64
import io
import logging
from pathlib import Path
from typing import Any

from mcp.types import ImageContent, TextContent

logger = logging.getLogger("hira-mcp-reader")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Excel ë¦¬ë” (openpyxl)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def read_excel(
    filepath: Path,
    *,
    sheet: str | None = None,
    cancer_type: str | None = None,
    max_rows: int = 200,
) -> list[TextContent]:
    """
    Excel íŒŒì¼ì„ ì½ì–´ Markdown í…Œì´ë¸”ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        filepath: .xlsx íŒŒì¼ ê²½ë¡œ
        sheet: ì‹œíŠ¸ ì´ë¦„ (Noneì´ë©´ í™œì„± ì‹œíŠ¸)
        cancer_type: ì•”ì¢… í•„í„° (ì˜ˆ: "ë‚œì†Œì•”", "ìê¶ê²½ë¶€ì•”")
        max_rows: ìµœëŒ€ ë°˜í™˜ í–‰ ìˆ˜ (í† í° ì œí•œ ë°©ì§€)

    Returns:
        list[TextContent] â€” Markdown í…Œì´ë¸” + ìš”ì•½ ì •ë³´
    """
    import openpyxl

    wb = openpyxl.load_workbook(str(filepath), data_only=True, read_only=False)

    if sheet:
        if sheet not in wb.sheetnames:
            return [TextContent(
                type="text",
                text=f"âš ï¸ ì‹œíŠ¸ '{sheet}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                     f"ì‚¬ìš© ê°€ëŠ¥í•œ ì‹œíŠ¸: {', '.join(wb.sheetnames)}"
            )]
        ws = wb[sheet]
    else:
        ws = wb.active

    # â”€â”€ ë¨¸ì§€ì…€ forward-fill ë§µ êµ¬ì¶• â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    merge_map: dict[tuple[int, int], Any] = {}
    for merged_range in ws.merged_cells.ranges:
        top_left_value = ws.cell(
            row=merged_range.min_row,
            column=merged_range.min_col,
        ).value
        for row in range(merged_range.min_row, merged_range.max_row + 1):
            for col in range(merged_range.min_col, merged_range.max_col + 1):
                merge_map[(row, col)] = top_left_value

    # â”€â”€ ë°ì´í„° ì¶”ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    all_rows: list[list[str]] = []
    for row_idx, row in enumerate(ws.iter_rows(values_only=False), start=1):
        cells: list[str] = []
        for cell in row:
            coord = (cell.row, cell.column)
            if coord in merge_map:
                val = merge_map[coord]
            else:
                val = cell.value
            cells.append(str(val).strip() if val is not None else "")
        all_rows.append(cells)

    wb.close()

    if not all_rows:
        return [TextContent(type="text", text="âš ï¸ ì‹œíŠ¸ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")]

    # â”€â”€ í—¤ë” ê°ì§€ (ì²« ë²ˆì§¸ ë¹„ì–´ìˆì§€ ì•Šì€ í–‰) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    header_idx = 0
    for i, row in enumerate(all_rows):
        if any(c for c in row):
            header_idx = i
            break

    headers = all_rows[header_idx]
    data_rows = all_rows[header_idx + 1:]

    # â”€â”€ ì•”ì¢… í•„í„° ì ìš© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if cancer_type:
        # ì£¼ë¡œ Cì—´(index 2) ë˜ëŠ” ì•”ì¢… ê´€ë ¨ ì»¬ëŸ¼ì—ì„œ í•„í„°
        cancer_col_idx = _find_cancer_column(headers)
        if cancer_col_idx is not None:
            data_rows = [
                row for row in data_rows
                if cancer_type in row[cancer_col_idx]
            ]

    total_count = len(data_rows)
    truncated = total_count > max_rows
    data_rows = data_rows[:max_rows]

    # â”€â”€ Markdown í…Œì´ë¸” ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    md_lines = _to_markdown_table(headers, data_rows)

    # â”€â”€ ìš”ì•½ ì •ë³´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    summary_parts = [
        f"ğŸ“Š ì‹œíŠ¸: {ws.title}",
        f"ğŸ“ ì „ì²´ í–‰: {total_count}í–‰",
    ]
    if cancer_type:
        summary_parts.append(f"ğŸ” í•„í„°: '{cancer_type}'")
    if truncated:
        summary_parts.append(f"âš ï¸ {max_rows}í–‰ê¹Œì§€ë§Œ í‘œì‹œ (ì „ì²´ {total_count}í–‰)")

    summary = " | ".join(summary_parts)

    return [TextContent(type="text", text=f"{summary}\n\n{md_lines}")]


def _find_cancer_column(headers: list[str]) -> int | None:
    """í—¤ë”ì—ì„œ ì•”ì¢… ê´€ë ¨ ì»¬ëŸ¼ ì¸ë±ìŠ¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    cancer_keywords = ["ì•”ì¢…", "cancer", "ì§ˆí™˜", "ì ì‘ì¦", "ì§„ë‹¨"]
    for idx, h in enumerate(headers):
        h_lower = h.lower()
        if any(kw in h_lower for kw in cancer_keywords):
            return idx
    # ê¸°ë³¸ fallback: Cì—´ (index 2) â€” HIRA ì—‘ì…€ ê´€í–‰
    if len(headers) > 2:
        return 2
    return None


def _to_markdown_table(headers: list[str], rows: list[list[str]]) -> str:
    """í—¤ë”ì™€ ë°ì´í„° í–‰ì„ Markdown í…Œì´ë¸” ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not headers:
        return "(ë¹ˆ í…Œì´ë¸”)"

    # ì—´ ìˆ˜ í†µì¼
    n_cols = len(headers)

    # ê¸´ ì…€ ë‚´ìš© ì¶•ì•½ (300ì ì´ˆê³¼ ì‹œ)
    def _trunc(s: str, limit: int = 300) -> str:
        return s[:limit] + "â€¦" if len(s) > limit else s

    header_line = "| " + " | ".join(_trunc(h) for h in headers) + " |"
    sep_line = "| " + " | ".join("---" for _ in headers) + " |"

    data_lines = []
    for row in rows:
        # ì—´ ìˆ˜ê°€ í—¤ë”ë³´ë‹¤ ì ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ì±„ì›€
        padded = row[:n_cols] + [""] * max(0, n_cols - len(row))
        line = "| " + " | ".join(_trunc(c) for c in padded) + " |"
        data_lines.append(line)

    return "\n".join([header_line, sep_line] + data_lines)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PDF ë¦¬ë” (pdfplumber + PyMuPDF í•˜ì´ë¸Œë¦¬ë“œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# í˜ì´ì§€ íƒ€ì… ê°ì§€ ìƒìˆ˜
_TABLE_THRESHOLD = 1  # pdfplumberê°€ Nê°œ ì´ìƒ í…Œì´ë¸” ê°ì§€ ì‹œ â†’ ì´ë¯¸ì§€ ë Œë”ë§
_MAX_PAGES_PER_CALL = 50  # í•œ ë²ˆì— ì²˜ë¦¬í•  ìµœëŒ€ í˜ì´ì§€ (í† í° ì œí•œ ë°©ì§€)
_IMAGE_DPI = 150  # ImageContent í•´ìƒë„

# PDF ì„¹ì…˜ë³„ í‚¤ì›Œë“œ ë§¤í•‘ (í•­ì•”í™”í•™ìš”ë²• ê³µê³ ì „ë¬¸ êµ¬ì¡°)
PDF_SECTIONS: dict[str, list[str]] = {
    "ê°œìš”": ["ê°œìš”", "ì´ì¹™", "ì¼ë°˜ì›ì¹™"],
    "ê¸‰ì—¬ê¸°ì¤€": ["ê¸‰ì—¬ê¸°ì¤€", "ìš”ì–‘ê¸‰ì—¬"],
    "ì•½ì œëª©ë¡": ["ì•½ì œ", "ëª©ë¡"],
    "ë³„í‘œ": ["ë³„í‘œ", "[ë³„í‘œ"],
    "ë¶€ë¡": ["ë¶€ë¡", "ì°¸ê³ "],
}


def read_pdf(
    filepath: Path,
    *,
    pages: str | None = None,
    section: str | None = None,
) -> list[TextContent | ImageContent]:
    """
    PDFë¥¼ í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹ìœ¼ë¡œ ì½ìŠµë‹ˆë‹¤.

    - í…ìŠ¤íŠ¸ ì „ìš© í˜ì´ì§€ â†’ pdfplumber.extract_text() â†’ TextContent
    - í…Œì´ë¸” í¬í•¨ í˜ì´ì§€ â†’ PyMuPDF pixmap(DPI 150) â†’ ImageContent (base64 PNG)

    Args:
        filepath: .pdf íŒŒì¼ ê²½ë¡œ
        pages: í˜ì´ì§€ ë²”ìœ„ (ì˜ˆ: "1-10", "5", "1,3,7-10"). Noneì´ë©´ ì²˜ìŒ 50p.
        section: ì„¹ì…˜ í•„í„° (ì˜ˆ: "ê°œìš”", "ê¸‰ì—¬ê¸°ì¤€", "ë³„í‘œ"). í‚¤ì›Œë“œë¡œ ì‹œì‘ í˜ì´ì§€ íƒìƒ‰.

    Returns:
        list[TextContent | ImageContent] í˜¼í•© ë¦¬ìŠ¤íŠ¸
    """
    import fitz  # PyMuPDF
    import pdfplumber

    doc = fitz.open(str(filepath))
    total_pages = len(doc)

    # â”€â”€ í˜ì´ì§€ ë²”ìœ„ ê²°ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if section:
        page_indices = _find_section_pages(filepath, section, total_pages)
        if not page_indices:
            doc.close()
            return [TextContent(
                type="text",
                text=f"âš ï¸ ì„¹ì…˜ '{section}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                     f"ì‚¬ìš© ê°€ëŠ¥í•œ ì„¹ì…˜: {', '.join(PDF_SECTIONS.keys())}\n"
                     f"ì´ {total_pages}í˜ì´ì§€"
            )]
    elif pages:
        page_indices = _parse_page_range(pages, total_pages)
    else:
        # ê¸°ë³¸: ì²˜ìŒ 50í˜ì´ì§€
        page_indices = list(range(min(total_pages, _MAX_PAGES_PER_CALL)))

    # 50í˜ì´ì§€ ì œí•œ ì ìš©
    truncated = len(page_indices) > _MAX_PAGES_PER_CALL
    page_indices = page_indices[:_MAX_PAGES_PER_CALL]

    # â”€â”€ í˜ì´ì§€ë³„ íƒ€ì… ê°ì§€ + íŒŒì‹± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    results: list[TextContent | ImageContent] = []

    # ì‹œì‘ ë©”íƒ€ ì •ë³´
    meta = (
        f"ğŸ“„ PDF: {filepath.name} ({total_pages}p)\n"
        f"ğŸ“– í‘œì‹œ ë²”ìœ„: {_format_page_range(page_indices)} "
        f"({len(page_indices)}p)"
    )
    if truncated:
        meta += f"\nâš ï¸ {_MAX_PAGES_PER_CALL}p ì œí•œ ì ìš©ë¨"
    if section:
        meta += f"\nğŸ” ì„¹ì…˜ í•„í„°: '{section}'"
    results.append(TextContent(type="text", text=meta))

    # pdfplumberë¡œ í…Œì´ë¸” ê°ì§€
    pdf_plumber = pdfplumber.open(str(filepath))

    text_buffer: list[str] = []  # ì—°ì† í…ìŠ¤íŠ¸ í˜ì´ì§€ ë²„í¼

    for page_idx in page_indices:
        page_num = page_idx + 1  # 1-indexed

        # pdfplumberë¡œ í…Œì´ë¸” ê°ì§€
        try:
            plumber_page = pdf_plumber.pages[page_idx]
            tables = plumber_page.find_tables()
            has_tables = len(tables) >= _TABLE_THRESHOLD
        except Exception:
            has_tables = False

        if has_tables:
            # í…ìŠ¤íŠ¸ ë²„í¼ê°€ ìˆìœ¼ë©´ ë¨¼ì € flush
            if text_buffer:
                results.append(TextContent(
                    type="text", text="\n\n".join(text_buffer)
                ))
                text_buffer.clear()

            # í…Œì´ë¸” í˜ì´ì§€ â†’ ì´ë¯¸ì§€ ë Œë”ë§ (PyMuPDF)
            try:
                fitz_page = doc[page_idx]
                mat = fitz.Matrix(_IMAGE_DPI / 72, _IMAGE_DPI / 72)
                pix = fitz_page.get_pixmap(matrix=mat)
                png_bytes = pix.tobytes("png")

                b64_data = base64.b64encode(png_bytes).decode("ascii")

                results.append(TextContent(
                    type="text",
                    text=f"--- ğŸ“Š p.{page_num} (í…Œì´ë¸” í¬í•¨ â†’ ì´ë¯¸ì§€) ---"
                ))
                results.append(ImageContent(
                    type="image",
                    data=b64_data,
                    mimeType="image/png",
                ))
            except Exception as e:
                logger.warning(f"í˜ì´ì§€ {page_num} ì´ë¯¸ì§€ ë Œë”ë§ ì‹¤íŒ¨: {e}")
                # í´ë°±: í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
                text = _extract_text_safe(plumber_page, page_num)
                text_buffer.append(text)

        else:
            # í…ìŠ¤íŠ¸ ì „ìš© í˜ì´ì§€ â†’ pdfplumber í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = _extract_text_safe(plumber_page, page_num)
            text_buffer.append(text)

    # ë‚¨ì€ í…ìŠ¤íŠ¸ ë²„í¼ flush
    if text_buffer:
        results.append(TextContent(
            type="text", text="\n\n".join(text_buffer)
        ))

    pdf_plumber.close()
    doc.close()

    return results


def _extract_text_safe(plumber_page, page_num: int) -> str:
    """pdfplumber í˜ì´ì§€ì—ì„œ ì•ˆì „í•˜ê²Œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        text = plumber_page.extract_text() or ""
        if text.strip():
            return f"--- p.{page_num} ---\n{text.strip()}"
        else:
            return f"--- p.{page_num} (ë¹ˆ í˜ì´ì§€) ---"
    except Exception as e:
        return f"--- p.{page_num} (ì¶”ì¶œ ì‹¤íŒ¨: {e}) ---"


def _find_section_pages(
    filepath: Path, section: str, total_pages: int
) -> list[int]:
    """
    PDFì—ì„œ ì„¹ì…˜ í‚¤ì›Œë“œê°€ í¬í•¨ëœ í˜ì´ì§€ ë²”ìœ„ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.

    ì „ëµ: ì„¹ì…˜ ì‹œì‘ í˜ì´ì§€ë¥¼ ì°¾ì€ ë’¤, ë‹¤ìŒ ì„¹ì…˜ ì‹œì‘ê¹Œì§€ì˜ ë²”ìœ„ë¥¼ ë°˜í™˜.
    """
    import pdfplumber

    keywords = PDF_SECTIONS.get(section, [section])

    pdf = pdfplumber.open(str(filepath))
    start_page = None
    end_page = total_pages - 1

    # 1ì°¨: ì •í™•í•œ ì„¹ì…˜ í‚¤ì›Œë“œë¡œ ì‹œì‘ í˜ì´ì§€ íƒìƒ‰
    for i, page in enumerate(pdf.pages):
        text = (page.extract_text() or "").strip()
        if not text:
            continue

        # í˜ì´ì§€ì˜ ì²˜ìŒ 500ìì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰ (ì œëª©ì€ ìƒë‹¨ì— ìœ„ì¹˜)
        header = text[:500]
        if any(kw in header for kw in keywords):
            start_page = i
            break

    if start_page is None:
        pdf.close()
        return []

    # 2ì°¨: ë‹¤ìŒ ì„¹ì…˜ ì‹œì‘ì  íƒìƒ‰ (ìµœëŒ€ 100í˜ì´ì§€ ë²”ìœ„)
    other_section_keywords = []
    for sec_name, sec_kws in PDF_SECTIONS.items():
        if sec_name != section:
            other_section_keywords.extend(sec_kws)

    for i in range(start_page + 1, min(start_page + 100, total_pages)):
        text = (pdf.pages[i].extract_text() or "").strip()
        header = text[:500]
        if any(kw in header for kw in other_section_keywords):
            end_page = i - 1
            break

    pdf.close()

    return list(range(start_page, end_page + 1))


def _parse_page_range(pages_str: str, total: int) -> list[int]:
    """
    í˜ì´ì§€ ë²”ìœ„ ë¬¸ìì—´ì„ 0-indexed ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    ì§€ì› í˜•ì‹:
      - "5"       â†’ [4]
      - "1-10"    â†’ [0,1,...,9]
      - "1,3,7-10" â†’ [0,2,6,7,8,9]
    """
    result: list[int] = []
    for part in pages_str.split(","):
        part = part.strip()
        if "-" in part:
            start_s, end_s = part.split("-", 1)
            start = max(int(start_s.strip()) - 1, 0)
            end = min(int(end_s.strip()) - 1, total - 1)
            result.extend(range(start, end + 1))
        else:
            idx = int(part) - 1
            if 0 <= idx < total:
                result.append(idx)

    return sorted(set(result))


def _format_page_range(indices: list[int]) -> str:
    """0-indexed ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ëŒì´ ì½ê¸° ì¢‹ì€ í˜ì´ì§€ ë²”ìœ„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not indices:
        return "(ì—†ìŒ)"

    # ì—°ì† êµ¬ê°„ íƒì§€
    ranges: list[str] = []
    start = indices[0]
    prev = indices[0]

    for i in indices[1:]:
        if i == prev + 1:
            prev = i
        else:
            if start == prev:
                ranges.append(f"p.{start + 1}")
            else:
                ranges.append(f"p.{start + 1}-{prev + 1}")
            start = i
            prev = i

    if start == prev:
        ranges.append(f"p.{start + 1}")
    else:
        ranges.append(f"p.{start + 1}-{prev + 1}")

    return ", ".join(ranges)
